% (partly) Generated by Paperpile. Check out http://paperpile.com for more information.
% BibTeX export options can be customized via Settings -> BibTeX.

@article{hochreiter2001learning,
      title={Learning to learn using gradient descent},
        author={Hochreiter, Sepp and Younger, A and Conwell, Peter},
          journal={Artificial Neural Networksâ€”ICANN 2001},
            pages={87--94},
              year={2001},
                publisher={Springer}
}

@article{duan2016rl2,
      author    = {Yan Duan and
                         John Schulman and
                                            Xi Chen and
                                                           Peter L. Bartlett and
                                                                          Ilya Sutskever and
                                                                                         Pieter Abbeel},
        title     = {RL{\textdollar}{\^{}}2{\textdollar}: Fast Reinforcement Learning via
                           Slow Reinforcement Learning},
                url       = {http://arxiv.org/abs/1611.02779},
Year = {2016},
Eprint = {arXiv:1611.02779}
}

@article{wang2016learning,
      author    = {Jane X. Wang and
                         Zeb Kurth{-}Nelson and
                                            Dhruva Tirumala and
                                                           Hubert Soyer and
                                                                          Joel Z. Leibo and
                                                                                         R{\'{e}}mi Munos and
                                                                                                        Charles Blundell and
                                                                                                                       Dharshan Kumaran and
                                                                                                                                      Matt Botvinick},
Title = {Learning to reinforcement learn},
Year = {2016},
Eprint = {arXiv:1611.05763},
}
}

@article{espinosa2012development,
      title={Development and plasticity of the primary visual cortex},
        author={Espinosa, J Sebastian and Stryker, Michael P},
          journal={Neuron},
            volume={75},
              number={2},
                pages={230--249},
                  year={2012},
                    publisher={Elsevier}
}

@INPROCEEDINGS{Vasilkoski2011-ww,
title = "Review of stability properties of neural plasticity rules for implementation on memristive neuromorphic hardware",
booktitle = "The 2011 International Joint Conference on Neural Networks ({IJCNN})",
author = "Vasilkoski, Zlatko and Ames, Heather and Chandler, Ben and Gorchetchnikov, Anatoli and L\'{e}veill\'{e}, Jasmin and Livitz, Gennady and Mingolla, Ennio and Versace, Massimiliano",
pages = "2563--2569",
year =  2011,
}

@ARTICLE{Fanselow2016-gz,
title = "The Origins and Organization of Vertebrate Pavlovian Conditioning",
author = "Fanselow, Michael S and Wassum, Kate M",
affiliation = "Department of Psychology, University of California Los Angeles, Los Angeles, California 90095-1563. Department of Psychology, University of California Los Angeles, Los Angeles, California 90095-1563.",
abstract = "Pavlovian conditioning is the process by which we learn relationships between stimuli and thus constitutes a basic building block for how the brain constructs representations of the world. We first review the major concepts of Pavlovian conditioning and point out many of the pervasive misunderstandings about just what conditioning is. This brings us to a modern redefinition of conditioning as the process whereby experience with a conditional relationship between stimuli bestows these stimuli with the ability to promote adaptive behavior patterns that did not occur before the experience. Working from this framework, we provide an in-depth analysis of two examples, fear conditioning and food-based appetitive conditioning, which include a description of the only partially overlapping neural circuitry of each. We also describe how these circuits promote the basic characteristics that define Pavlovian conditioning, such as error-correction-driven regulation of learning.",
journal = "Cold Spring Harb. Perspect. Biol.",
volume =  8,
number =  1,
month =  jan,
year =  2016,
}


@ARTICLE{Graves2014-ch,
title = "Neural Turing Machines",
author = "Graves, Alex and Wayne, Greg and Danihelka, Ivo",
abstract = "We extend the capabilities of neural networks by coupling them to external memory resources, which they can interact with by attentional processes. The combined system is analogous to a Turing Machine or Von Neumann architecture but is differentiable end-to-end, allowing it to be efficiently trained with gradient descent. Preliminary results demonstrate that Neural Turing Machines can infer simple algorithms such as copying, sorting, and associative recall from input and output examples.",
month =  oct,
year =  2014,
archivePrefix = "arXiv",
primaryClass = "cs.NE",
eprint = "1410.5401"
}

@INCOLLECTION{Sukhbaatar2015-ly,
title = "{End-To-End} Memory Networks",
booktitle = "Advances in Neural Information Processing Systems 28",
author = "Sukhbaatar, Sainbayar and Szlam, Arthur and Weston, Jason and Fergus, Rob",
editor = "Cortes, C and Lawrence, N D and Lee, D D and Sugiyama, M and Garnett, R",
publisher = "Curran Associates, Inc.",
pages = "2440--2448",
year =  2015
}

@ARTICLE{Santoro2016-jn,
title = "One-shot Learning with {Memory-Augmented} Neural Networks",
author = "Santoro, Adam and Bartunov, Sergey and Botvinick, Matthew and Wierstra, Daan and Lillicrap, Timothy",
abstract = "Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of ``one-shot learning.'' Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training. When new data is encountered, the models must inefficiently relearn their parameters to adequately incorporate the new information without catastrophic interference. Architectures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information, and hence can potentially obviate the downsides of conventional models. Here, we demonstrate the ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples. We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory location-based focusing mechanisms.",
month =  "19~" # may,
year =  2016,
annote = "- Quite confusing...<div><br></div><div>- Input is downsampled, flattened images of characters w/ labels</div><div><br></div><div>- Controller is an lstm that uses input and state to produce 'memory key'. The key is used to retrieve a blend of memories that look most like the key, and is then written to memory at either the most recent or least-used location (is that determined by the controller or by a hard-learned parameter?)</div><div><br></div><div>- Somehow the system, and human, get better than chance accuracy in character classification on first presentation?? How is that possible? - Oh, yes: if you have already seen characters from many classes, then characters not looking like any of them likely to belong to the remaining class! Clever for the network to be able to see that...</div><div><br></div><div>- Also: how is performance from simple FF NN + kNN so terrible? Well, the FF is pretty bad - simple auto-encoder. A full CNN might do much better - though as they observe, it would have many more parameters..</div><div><br></div><div>- But the auto-encoder is trained unsupervised, while the MANN is trained supervised !... maybe unfair baseline...</div>",
archivePrefix = "arXiv",
primaryClass = "cs.LG",
eprint = "1605.06065"
}

@ARTICLE{Blackman2016-jx,
title = "Monkey Prefrontal Neurons Reflect Logical Operations for Cognitive Control in a Variant of the {AX} Continuous Performance Task ({AX-CPT})",
author = "Blackman, Rachael K and Crowe, David A and DeNicola, Adele L and Sakellaridi, Sofia and MacDonald, 3rd, Angus W and Chafee, Matthew V",
journal = "J. Neurosci.",
volume =  36,
number =  14,
pages = "4067--4079",
month =  "6~" # apr,
year =  2016,
keywords = "context processing; macaque; neural activity; prefrontal; primate; schizophrenia",
language = "en"
}


@ARTICLE{Soltoggio2013-rg,
    title = "Solving the distal reward problem with rare correlations",
    author = "Soltoggio, Andrea and Steil, Jochen J",
    affiliation = "Research Institute for Cognition and Robotics and Faculty of
        Technology, Bielefeld University, Bielefeld 33615, Germany.
        asoltogg@cor-lab.uni-bielefeld.de",
    abstract = "In the course of trial-and-error learning, the results of
        actions, manifested as rewards or punishments, occur often seconds after
        the actions that caused them. How can a reward be associated with an
        earlier action when the neural activity that caused that action is no
        longer present in the network? This problem is referred to as the distal
        reward problem. A recent computational study proposes a solution using
        modulated plasticity with spiking neurons and argues that precise firing
        patterns in the millisecond range are essential for such a solution. In
        contrast, the study reported in this letter shows that it is the rarity
        of correlating neural activity, and not the spike timing, that allows
        the network to solve the distal reward problem. In this study, rare
        correlations are detected in a standard rate-based computational model
        by means of a threshold-augmented Hebbian rule. The novel modulated
        plasticity rule allows a randomly connected network to learn in
        classical and instrumental conditioning scenarios with delayed rewards.
        The rarity of correlations is shown to be a pivotal factor in the
        learning and in handling various delays of the reward. This study
        additionally suggests the hypothesis that short-term synaptic plasticity
        may implement eligibility traces and thereby serve as a selection
        mechanism in promoting candidate synapses for long-term storage.",
    journal = "Neural Comput.",
    volume =  25,
    number =  4,
    pages = "940--978",
    month =  apr,
    year =  2013,
}



